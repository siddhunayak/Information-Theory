# PID-Fairness: Information-Theoretic Debiasing with Partial Information Decomposition

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange.svg)](https://pytorch.org/)

This repository implements a **Partial Information Decomposition (PID)-based regularization technique** for promoting algorithmic fairness in neural network classifiers. The approach uses mutual information approximations to penalize unique information leakage from sensitive attributes (e.g., gender) into predictions, conditional on true labels. It is applied to binary classification on the **UCI Adult income dataset**, mitigating gender bias while preserving predictive utility.

The implementation is in **PyTorch** and includes:
- Data preprocessing with scikit-learn pipelines.
- Custom PID loss module using mutual information estimators.
- Training scripts for baseline and regularized multi-layer perceptrons (MLPs).
- Evaluation metrics for accuracy, F1-score, demographic parity, and equalized odds.


## ðŸš€ Quick Start

### Prerequisites
- Python 3.8+
- PyTorch 2.0+
- scikit-learn 1.4+
- NumPy, Pandas

### Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/pid-fairness.git
   cd pid-fairness
   ```

2. Create a virtual environment and install dependencies:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

   `requirements.txt` contents:
   ```
   torch>=2.0.0
   scikit-learn>=1.4.0
   numpy
   pandas
   scipy
   ```

### Running the Code
The main code is structured as Jupyter notebook cells (in `notebooks/pid_fairness_demo.ipynb`). To run:

1. Launch Jupyter:
   ```bash
   jupyter notebook notebooks/pid_fairness_demo.ipynb
   ```

2. Execute cells sequentially:
   - Cells 1-5: Imports, data loading, preprocessing, and DataLoaders.
   - Cell 6: MLP model definition.
   - Cell 7: PID approximation and loss module.
   - Cells 8-9: Training baseline and PID-regularized models.
   - Cell 10: Fairness evaluation.

Expected output:
- Baseline model: ~85% accuracy, DP diff ~0.15.
- PID model (Î»=1.0): ~84.9% accuracy, DP diff ~0.08 (reduced bias).

For script-based execution, convert to `train.py`:
```bash
python scripts/train.py --lambda 1.0 --epochs 5
```

## ðŸ“Š Results
Key findings from experiments on Adult dataset (24k train, 8k test):

| Model          | Accuracy | F1-Score | DP Difference | EO Difference |
|----------------|----------|----------|---------------|---------------|
| Baseline      | 0.852   | 0.841   | 0.152        | 0.089        |
| PID (Î»=1.0)   | 0.849   | 0.838   | 0.078        | 0.045        |

- PID reduces bias by ~50% with <1% utility drop.
- Hyperparameter: Î» controls trade-off (optimal ~1.0).



## ðŸ”¬ Technical Details
- **Dataset**: UCI Adult (income prediction, gender as sensitive attribute).
- **Model**: 2-layer MLP (128â†’64â†’1) with ReLU and dropout.
- **Loss**: BCE + Î» * PID (unique info proxy: max(MI(Å¶;A) - MI(Å¶;Y), 0)).
- **MI Estimation**: Discrete via `sklearn.mutual_info_classif`.
- **Fairness Metrics**:
  - Demographic Parity Diff: |P(Å¶=1|A=1) - P(Å¶=1|A=0)|
  - Equal Opportunity Diff: |TPR(A=1) - TPR(A=0)|



